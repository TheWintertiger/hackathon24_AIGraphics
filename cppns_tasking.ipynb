{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook is adapted from https://datalore.jetbrains.com/report/static/2jrFAfMBVhUsYW8njXgysC/9OuleGiEVhxqGen1GS9cjN?_ga=2.8213810.1854649308.1715236946-557222550.1715236946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed modules\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageChops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build a network\n",
    "def build_network_demo(width=4, depth=4, variance=400, seed=42):\n",
    "    if not (width > 0 and depth > 0 and variance > 0):\n",
    "        #ensure valid parameters\n",
    "        raise ValueError\n",
    "    \n",
    "    #to make network repeatable, we set a seed to generator\n",
    "    tf.random.set_seed(seed)\n",
    "    input_shape = (5,)  # number of parameters in input space defined above. x position, y position, alpha/beta for animation, and f for defining shape\n",
    "    \n",
    "    #specific initializer to ensure a pretty image. May be interesting to test others\n",
    "    initializer = keras.initializers.VarianceScaling(scale=variance,\n",
    "                                                     mode='fan_in',\n",
    "                                                     distribution='normal',\n",
    "                                                     seed=seed)\n",
    "    #now we use Keras to build the network shape\n",
    "\n",
    "    #first we set number of input parameters\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    #depth defines how many hidden layers the network will have betwee, its input and its output\n",
    "    for _ in range(depth):\n",
    "        #create a layer. It will have width outputs along with a tanh activation (output is squashed to -1 to 1)\n",
    "        #num of inputs is determined automaticaly based on previous layer\n",
    "        layer = keras.layers.Dense(width, kernel_initializer=initializer, activation='tanh')\n",
    "        #add the layer to the network\n",
    "        layer_output = layer(x)\n",
    "        x = keras.layers.Concatenate()([x, layer_output])\n",
    "\n",
    "    #add the final layer, which will output a single RGB value as the result\n",
    "    bottleneck_initializer = keras.initializers.GlorotNormal(seed)\n",
    "    bottleneck = keras.layers.Dense(3,  # The number of channels in RGB image\n",
    "                                    activation='tanh',\n",
    "                                    kernel_initializer=bottleneck_initializer)(x)\n",
    "    \n",
    "    #create a keras Model from the layers and return it\n",
    "    model = keras.Model(inputs=inputs, outputs=bottleneck)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image size\n",
    "Change the \"res\" value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets build the input space. We need 5 \"images\", starting with encoding the image position\n",
    "#use a square image of wished sizes\n",
    "ress = [256, 512]\n",
    "\n",
    "x_poss = []\n",
    "y_poss = []\n",
    "\n",
    "for res in ress:\n",
    "  #get x values, linear from -1 to 1\n",
    "  x_poss.append(np.linspace(-1,1,res))\n",
    "  y_poss.append(np.linspace(-1,1,res))\n",
    "\n",
    "  #expand the 1d arrays to two grids\n",
    "  x_poss[len(x_poss) - 1], y_poss[len(y_poss) - 1] = np.meshgrid(x_poss[len(x_poss) - 1],y_poss[len(y_poss) - 1])\n",
    "\n",
    "  #display the two images with plt\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.subplot(1,2,1)\n",
    "  plt.imshow(x_poss[len(x_poss) - 1])\n",
    "\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.imshow(y_poss[len(y_poss) - 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, alpha and beta are set to constant\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.4\n",
    "\n",
    "#expand for whole image\n",
    "\n",
    "alphas_filled = []\n",
    "betas_filled = []\n",
    "\n",
    "for x_pos in x_poss:\n",
    "  alphas_filled.append(np.full(x_pos.shape, alpha))\n",
    "  betas_filled.append(np.full(x_pos.shape, beta))\n",
    "\n",
    "  print(alphas_filled[len(alphas_filled) - 1].shape)\n",
    "  print(betas_filled[len(betas_filled) - 1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Shape function\" init\n",
    "\n",
    "We can control the overall shape of the generated gradient using the f parameter.\n",
    "If we map it to the distance from the center, it will result in a circular shape, but we can also use a diamond shape or just linearly along\n",
    "the diagonal.\n",
    "\n",
    "Comment out the f parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the f \"shape function\". Use a circular shape, meaning f will be distance from center\n",
    "\n",
    "fs = []\n",
    "\n",
    "for idx in range(len(x_poss)):\n",
    "  #fs.append(np.sqrt(x_poss[idx] ** 2 + y_poss[idx] ** 2))\n",
    "\n",
    "  #alternative: diamond shape\n",
    "  fs.append(abs(x_poss[idx]) + abs(y_poss[idx]))\n",
    "\n",
    "  #or just diagonal\n",
    "  #fs.append(x_poss[idx] + y_poss[idx])\n",
    "\n",
    "\n",
    "  plt.figure(figsize=(5,5))\n",
    "  plt.imshow(fs[len(fs) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the 5 images into what our model expects: num_pixels batches of 5 values\n",
    "\n",
    "batches = []\n",
    "\n",
    "for idx in range(len(x_poss)):\n",
    "  #flatten each of the images\n",
    "  x_pos_flat = x_poss[idx].reshape(-1,1)\n",
    "  y_pos_flat = y_poss[idx].reshape(-1,1)\n",
    "  f_flat = fs[idx].reshape(-1,1)\n",
    "  alpha_filled_flat = alphas_filled[idx].reshape(-1,1)\n",
    "  beta_filled_flat = betas_filled[idx].reshape(-1,1)\n",
    "  #concatenate into one array\n",
    "  concat = np.array((x_pos_flat,y_pos_flat,alpha_filled_flat,beta_filled_flat,f_flat))\n",
    "\n",
    "  print(concat.shape)\n",
    "\n",
    "  #reshape: remove empty dim, ensure end result is res*res batches of 5 input values\n",
    "  batches.append(np.concatenate(concat, axis=1))\n",
    "\n",
    "  print(batches[len(batches) - 1].shape)\n",
    "  print(batches[len(batches) - 1][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model complexity\n",
    "\n",
    "The below code will initialize the model and calculate the final pattern. Change the depth/width/variance/seed parameters to generate different patterns.\n",
    "\n",
    "Configure:\n",
    "* depth/width: 1+; the bigger the number, more time it will take\n",
    "* variance: up to approx. 10.000, but not really limited\n",
    "* seed: any number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network parameters. These increase the complexity of the model, which usually means more complex patterns\n",
    "depth=10\n",
    "width=4\n",
    "\n",
    "#a lower variance will result in a smoother, more blurred image, while a higher one results in sharper edges\n",
    "variance=10\n",
    "\n",
    "#random seed. Changing the seed will result in a completely different pattern\n",
    "seed=88\n",
    "\n",
    "\n",
    "#initialize the model with the given parameters\n",
    "model = build_network_demo(depth=depth, width=width, variance=variance, seed=seed)\n",
    "#feed the data and save the resulting image into pred\n",
    "preds = []\n",
    "for batch in batches:\n",
    "  preds.append(model.predict(batch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the result and display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_normalized = []\n",
    "for idx in range(len(preds)):\n",
    "  preds_normalized.append((preds[idx]-preds[idx].min(0)) / (preds[idx].ptp(0) + 1e-10))\n",
    "  plt.imshow(preds_normalized[len(preds_normalized) - 1].reshape(ress[idx],ress[idx],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JetBrains recoloring code\n",
    "\n",
    "Below is code that JetBrains used to recolor the random pattern into brand colors. Not sure exactly how it works,\n",
    "or how to make it produce different colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_params = {\n",
    "    'grayscale_matrix': [0.3, 0.3, 0.3, 0.0, 0.3, 0.3, 0.3, 0.0, 0.3, 0.3, 0.3, 0.0],\n",
    "    'red_component': [0, 0.11568627450980393, 0.3254901960784314, 0.23137254901960785, 0.4196078431372549,\n",
    "                      0.027450980392156862, 1],\n",
    "    'green_component': [0, 0.4588235294117647, 0.6294117647058823, 0.9176470588235294, 0.3411764705882353,\n",
    "                        0.7647058823529411, 1],\n",
    "    'blue_component': [0, 0.19215686274509805, 0.692156862745098, 0.3843137254901961, 1, 0.9490196078431372, 1],\n",
    "    'color_matrix': [1.3935000000000002, -0.35750000000000004, -0.03599999999999999, 0,\n",
    "                     -0.10650000000000001, 1.1425, -0.03599999999999999, 0,\n",
    "                     -0.10650000000000001, -0.35750000000000004, 1.4640000000000002, 0]\n",
    "}\n",
    "\n",
    "def component_transfer(grayscale: np.ndarray, component: list) -> np.ndarray:\n",
    "    n = len(component) - 1\n",
    "\n",
    "    def precompute_transfer(x):\n",
    "        if x == 1:\n",
    "            return component[-1]\n",
    "        k = int(x * n)\n",
    "        x_new = component[k] + (x - k / n) * n * (component[k + 1] - component[k])\n",
    "        return round(x_new * 255)\n",
    "\n",
    "    transfer_lookup = {x: precompute_transfer(x / 255) for x in range(256)}\n",
    "    gradientmap = np.vectorize(transfer_lookup.get)(grayscale)\n",
    "    return gradientmap\n",
    "\n",
    "def recolor_image(source_img: Image) -> Image:\n",
    "    grayscale = source_img.convert('RGB', color_params['grayscale_matrix'])\n",
    "    grayscale_arr = np.array(grayscale)\n",
    "    gradientmap_arr = np.zeros(grayscale_arr.shape, dtype=np.uint)\n",
    "    gradientmap_arr[:, :, 0] = component_transfer(grayscale_arr[:, :, 0], color_params['red_component'])\n",
    "    gradientmap_arr[:, :, 1] = component_transfer(grayscale_arr[:, :, 1], color_params['green_component'])\n",
    "    gradientmap_arr[:, :, 2] = component_transfer(grayscale_arr[:, :, 2], color_params['blue_component'])\n",
    "    gradientmap = Image.fromarray(gradientmap_arr.astype(np.uint8))\n",
    "    blended = ImageChops.multiply(gradientmap, grayscale)\n",
    "    result_img = blended.convert('RGB', color_params['color_matrix'])\n",
    "    return result_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple recoloring\n",
    "\n",
    "This way of recoloring simply maps different grayscale values to different colors.\n",
    "Values and colors should be same lenght, defining which grayscale value will be mapped to which color, interpolating inbetween.\n",
    "\n",
    "Channel defines which channel of the pattern will be used, other 2 will be ignored\n",
    "\n",
    "values: more possible, color: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way would be to just map a grayscale image to colors, eg:\n",
    "#0 equals black, 0.5 equals red, 1.0 equals blue, then interpolate between these values\n",
    "\n",
    "def interpolate(x, values, colors):\n",
    "    assert len(values) == len(colors)\n",
    "\n",
    "    prev_v = 0\n",
    "    prev_col = np.array([0,0,0])\n",
    "\n",
    "    for v, col in zip(values,colors):\n",
    "        #print(prev_v, v,x)\n",
    "        if v >= x:\n",
    "            i_value = (x-prev_v)/(v-prev_v)\n",
    "            return i_value*col+(1-i_value)*prev_col\n",
    "        else:\n",
    "            prev_v = v\n",
    "            prev_col = col\n",
    "\n",
    "    assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a color for each grayscale value, to interpolate\n",
    "#values: final one must be 1.0, while 0 is always black, the number should go from 0 > 1\n",
    "\n",
    "values = [0.2,0.7,1.0]\n",
    "\n",
    "colors = np.array([\n",
    "    [0.7,0.55,0.1],   #R\n",
    "    [0.1,0.1,0.9],    #B\n",
    "    [0,1,1]])         #G\n",
    "\n",
    "channel = 0\n",
    "\n",
    "recolors = []\n",
    "for idx in range(len(preds_normalized)):\n",
    "  recolors.append([interpolate(i,values,colors) for i in preds_normalized[idx][:,channel]])\n",
    "  recolors[len(recolors) - 1] = np.array(recolors[len(recolors) - 1])\n",
    "  recolors[len(recolors) - 1] = recolors[len(recolors) - 1].reshape(ress[idx],ress[idx],3)\n",
    "\n",
    "  plt.imshow(recolors[len(recolors) - 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the images in all the sizes\n",
    "\n",
    "Import the image to Krita for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "SUBFOLDER = \"generated_resized_srcs\"\n",
    "\n",
    "if not os.path.exists(SUBFOLDER):\n",
    "  os.makedirs(SUBFOLDER)\n",
    "\n",
    "base_id = 0\n",
    "for file in os.listdir(SUBFOLDER):\n",
    "  tokenized = os.path.basename(file).split('_')\n",
    "  base_id = int(tokenized[0]) + 1\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "for idx in range(len(recolors)):\n",
    "  img_arr = recolors[idx]\n",
    "  img_arr = img_arr-img_arr.min()\n",
    "  img_arr = img_arr/(img_arr.max()+1e-10)\n",
    "  img_arr = (img_arr * 255).astype(np.uint8)\n",
    "  img = Image.fromarray(img_arr)\n",
    "  \n",
    "  id_str = now.strftime(\"%d%m%Y_%H_%M_%S\")\n",
    "  id_str = f'{base_id}_{id_str}'\n",
    "  img.save(f\"{SUBFOLDER}/{id_str}_{ress[idx]}x{ress[idx]}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
